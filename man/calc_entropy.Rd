% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/entropy.R
\name{calc_entropy}
\alias{calc_entropy}
\title{Calculate Shannon Entropy}
\usage{
calc_entropy(prob)
}
\arguments{
\item{prob}{Vector. Vector of probabilities (ex. frequencies of nucleotides in a column of a MSA)}
}
\value{
Double. Shannon entropy value.
}
\description{
This function apply the formula for the Shannon entropy for a vector of probabilities (!!!not absolute frequencies!!!).
\deqn{H = -\sum_{i=1}^n p_i \log_2(p_i)}
where:
\itemize{
\item \eqn{H} is the Shannon entropy.
\item \eqn{p_i} is the proportion of occurrences of the \eqn{i}-th category (e.g., nucleotide or amino acid frequency).
\item The logarithm is base 2.
}
}
\details{
Shannon entropy is highest when all categories are equally likely and is lowest (zero) when one category dominates completely.
}
